{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef6d5ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d219d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3365, 0.1532, 0.1201],\n",
      "        [0.9913, 0.3697, 0.9086],\n",
      "        [0.2524, 0.2583, 0.7079],\n",
      "        [0.6834, 0.1948, 0.2482],\n",
      "        [0.8929, 0.4685, 0.6124]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a178d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype = torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9425ede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 根据数据创建tensor\n",
    "x = torch.tensor([1,2,3,4])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b793969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype = torch.float64)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "833c147a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "#获取Tensor的形状\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614a0c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2607, 1.7727, 1.4493],\n",
      "        [1.1094, 1.6944, 1.4191],\n",
      "        [1.1927, 1.8335, 1.6555],\n",
      "        [1.8439, 1.6673, 1.4369],\n",
      "        [1.2017, 1.9844, 1.4831]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#加法\n",
    "y = torch.rand(5,3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50e8bc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2607, 1.7727, 1.4493],\n",
      "        [1.1094, 1.6944, 1.4191],\n",
      "        [1.1927, 1.8335, 1.6555],\n",
      "        [1.8439, 1.6673, 1.4369],\n",
      "        [1.2017, 1.9844, 1.4831]])\n"
     ]
    }
   ],
   "source": [
    "#加法(指定输出）\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y,out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8bfbfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2., dtype=torch.float64)\n",
      "tensor(2., dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#数据是共享内存的\n",
    "y= x[0,1]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1ebbed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4015, 0.7799, 0.4022, 0.8549, 0.8857, 0.5185, 0.7383, 0.0270, 0.5995,\n",
      "        0.4318, 0.2129, 0.7337, 0.8553, 0.2500, 0.9146])\n",
      "tensor([[0.4015, 0.7799, 0.4022],\n",
      "        [0.8549, 0.8857, 0.5185],\n",
      "        [0.7383, 0.0270, 0.5995],\n",
      "        [0.4318, 0.2129, 0.7337],\n",
      "        [0.8553, 0.2500, 0.9146]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,5)\n",
    "y = x.view(15)\n",
    "print(y)\n",
    "z = x.view(-1,3)\n",
    "print(z)\n",
    "#注意，y和z都是共享x的内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b16d286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4015, 0.7799, 0.4022, 0.8549, 0.8857, 0.5185, 0.7383, 0.0270, 0.5995,\n",
      "        0.4318, 0.2129, 0.7337, 0.8553, 0.2500, 0.9146])\n"
     ]
    }
   ],
   "source": [
    "x_Copy = x.clone().view(15)\n",
    "print(x_Copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f83ba3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4496674537658691\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1) #tensor标量\n",
    "print(x.item()) #转换为python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "367c923a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5846, 0.5523, 0.9819, 0.2047],\n",
      "        [0.8135, 0.6912, 0.9347, 0.2078],\n",
      "        [0.6514, 0.9669, 0.8661, 0.4656],\n",
      "        [0.3550, 0.7614, 0.4696, 0.0785]])\n",
      "tensor(2.2205)\n",
      "tensor([0.5846, 0.6912, 0.8661, 0.0785])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "print(x)\n",
    "print(x.trace())\n",
    "print(x.diag())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "871b4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "#广播机制：两个形状不同的tensor按元素运算时，可能触发\n",
    "x = torch.arange(1,3).view(1,2)\n",
    "y = torch.arange(1,4).view(3,1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(x + y) \n",
    "#广播机制：x的第一行的元素被复制到第二行、第三行、y中的第一列元素被复制到了第二列。\n",
    "#如此，二者就可以作加法运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba5433a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#内存特性\n",
    "id_before = id(y)\n",
    "y = x + y #y指向新内存\n",
    "id_new = id(y)\n",
    "print(id_before == id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9a812eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#内存特性\n",
    "id_before = id(y)\n",
    "y[:] = x + y #结果施加到原有的y：inplace\n",
    "id_new = id(y)\n",
    "print(id_before == id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "83d0e90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#内存特性\n",
    "id_before = id(y)\n",
    "torch.add(x,y,out = y)#利用原有的y作为输出：inplace\n",
    "id_new = id(y)\n",
    "print(id_before == id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5aa6e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16c73cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x,device = device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eadfeb",
   "metadata": {},
   "source": [
    "# 自动求梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66394856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "print(x.grad_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d3310f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "z = y ** 2 * 3\n",
    "out = z.mean() #因为out是一个标量，所以调用backward()时不需要指定求导变量：\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "026ca39d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad) #out关于x的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0b935ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "out3 = x.sum()\n",
    "# grad在反向传播过程中是累加的，每一次反向传播运行，都会累加之前的梯度。\n",
    "# 所以需要把梯度清零。\n",
    "x.grad.data.zero_() \n",
    "out3.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfcb6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
